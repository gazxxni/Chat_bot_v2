# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import chromadb
from chromadb.utils import embedding_functions
import os
from dotenv import load_dotenv
from openai import OpenAI  # â­ï¸ Google ëŒ€ì‹  OpenAIë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

# â”€â”€â”€ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
# â­ï¸ OpenAI í‚¤ë§Œ ë¶ˆëŸ¬ì˜¤ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# â”€â”€â”€ OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â­ï¸ OpenAI API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€ ChromaDB í´ë¼ì´ì–¸íŠ¸ ë° ì»¬ë ‰ì…˜ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ChromaDB ì„¤ì •ì€ text-embedding-3-smallì„ ì´ë¯¸ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
chroma_client = chromadb.PersistentClient(path="./chroma_db")
embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
    api_key=OPENAI_API_KEY,
    model_name="text-embedding-3-small"
)

collection_semantic = chroma_client.get_or_create_collection(
    name="semantic_education_chunks",
    embedding_function=embedding_fn
)

# â”€â”€â”€ FastAPI ì•± ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

# â”€â”€â”€ CORS ì„¤ì • (React í”„ë¡ íŠ¸ í—ˆìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€ ìš”ì²­ ë°”ë”” ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class QueryRequest(BaseModel):
    query: str

# â”€â”€â”€ ì§ˆë¬¸ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/ask")
async def ask_question(request: QueryRequest):
    query = request.query.strip()
    top_k = 10

    # ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    try:
        results_semantic = collection_semantic.query(query_texts=[query], n_results=top_k)
    except Exception as e:
        return {"answer": f"DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    retrieved_docs = []
    if results_semantic.get("documents"):
        retrieved_docs.extend(results_semantic["documents"][0])

    if not retrieved_docs:
        retrieved_docs = ["ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]

    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ì œ (ì¤‘ë³µ ì œê±°, 3ê°œ ì œí•œ, 1500ì ì œí•œ)
    retrieved_docs = list(dict.fromkeys(retrieved_docs))[:10]
    context = "\n".join(retrieved_docs)[:1500]

    # â­ï¸ OpenAI GPT ëª¨ë¸ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì‹œìŠ¤í…œ/ì‚¬ìš©ì ë¶„ë¦¬)
    
    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ì±—ë´‡ì˜ ì—­í• ê³¼ ë§íˆ¬ ì •ì˜
    system_prompt = """
    ë‹¹ì‹ ì€ ì»´í“¨í„°ê³µí•™ê³¼ ì‹ ì…ìƒë“¤ì˜ ê³¼ëª© ì„ íƒì„ ë„ì™€ì£¼ëŠ” ì¡°êµ ì±—ë´‡ì…ë‹ˆë‹¤.
    í•™ìƒë“¤ì€ ê³¼ëª© ìˆœì„œ, íŠ¸ë™ êµ¬ì„±, ì§„ë¡œì™€ ê´€ë ¨ëœ ìˆ˜ì—…ì„ ê³ ë¯¼í•˜ê³  ìˆìœ¼ë©°, 
    ë‹¹ì‹ ì€ ì´ë“¤ì—ê²Œ ë§ˆì¹˜ ìƒë‹´ ì„ ìƒë‹˜ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ ì¤ë‹ˆë‹¤.
    ê¸°ìˆ  ìš©ì–´(ì˜ˆ: ìœ„ìƒì •ë ¬, ìµœë‹¨ê²½ë¡œ)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , 
    ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. 
    "ë¨¼ì € ~ì„ ë“£ê³ , ê·¸ ë‹¤ìŒ ~ì„ ë“£ëŠ” ê²Œ ì¢‹ì•„ìš”" ê°™ì€ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. 
    ì¤‘ìš”í•œ ê³¼ëª©ì€ ê°•ì¡°í•´ë„ ì¢‹ì•„ìš”. 
    í•™ìƒë“¤ì´ í—·ê°ˆë¦¬ì§€ ì•Šë„ë¡ ìˆœì„œë¥¼ ì •ë¦¬í•´ì„œ ë§í•´ ì£¼ì„¸ìš”.
    ì£¼ì˜: ë‹µë³€ì—ëŠ” `*`, `**`, `-`, `â€¢` ë“±ê³¼ ê°™ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ì•„ ì£¼ì„¸ìš”. 
    í•„ìš”í•œ ê²½ìš° ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ê°•ì¡°í•´ì£¼ì„¸ìš”.
    """

    # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: ì‹¤ì œ ë§¥ë½(context)ê³¼ ì§ˆë¬¸(query) ì „ë‹¬
    user_prompt = f"""
    ë‹¤ìŒì€ ì°¸ê³  ì •ë³´ì…ë‹ˆë‹¤:
    {context}

    í•™ìƒì˜ ì§ˆë¬¸:
    {query}
    """

    # â­ï¸ Gemini í˜¸ì¶œ ëŒ€ì‹  OpenAI GPT ëª¨ë¸ í˜¸ì¶œ
    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # ë˜ëŠ” "gpt-3.5-turbo", "gpt-4o-mini" ë“±
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        # â­ï¸ ì‘ë‹µ êµ¬ì¡°ê°€ ë‹¤ë¥´ë¯€ë¡œ .text ëŒ€ì‹  .choices[0].message.content ì‚¬ìš©
        return {"answer": response.choices[0].message.content}
    
    except Exception as e:
        # â­ï¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë³€ê²½
        return {"answer": f"OpenAI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

# â”€â”€â”€ ê¸°ë³¸ ë£¨íŠ¸ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/")
def root():
    return {"message": "ì»´ê³µë„ìš°ë¯¸ë´‡ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ ğŸš€"}